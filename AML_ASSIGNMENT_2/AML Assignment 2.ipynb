{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "049ba707-df87-47ff-a17e-b76f93019249",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "049ba707-df87-47ff-a17e-b76f93019249",
        "outputId": "dd4b4235-444a-4b2f-a497-cf63cf8586a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-005d00da-4c0b-4a2b-8fe0-b790f924abd7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-005d00da-4c0b-4a2b-8fe0-b790f924abd7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"harshikutty\",\"key\":\"18db70790316a26eb1a34aa1e79a33a1\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# To upload the kaggle.json file\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7b33ee53-20f8-4f8f-8c04-bccbfd7e3d0e",
      "metadata": {
        "id": "7b33ee53-20f8-4f8f-8c04-bccbfd7e3d0e"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "\n",
        "# Changing the prath to the .kaggle folder\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#  Changing the permissions to perform read and write access\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "28ceabf6-fcf8-4600-a5bf-d2e7cabdf4f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28ceabf6-fcf8-4600-a5bf-d2e7cabdf4f7",
        "outputId": "5c18f8b2-d004-4df8-fa80-3cccb7c7999d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 98% 795M/812M [00:03<00:00, 299MB/s]\n",
            "100% 812M/812M [00:03<00:00, 218MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Downloading the dogs-vs-cats dataset\n",
        "!kaggle competitions download -c dogs-vs-cats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "94f46dc6-cfb6-4437-a419-6e637b401523",
      "metadata": {
        "id": "94f46dc6-cfb6-4437-a419-6e637b401523"
      },
      "outputs": [],
      "source": [
        "# Unzipping dogs-vs-cats dataset file\n",
        "!unzip -qq dogs-vs-cats.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d798963b-0779-447c-9b6b-6fbc2c94a16a",
      "metadata": {
        "id": "d798963b-0779-447c-9b6b-6fbc2c94a16a"
      },
      "outputs": [],
      "source": [
        "# Unzipping train sample\n",
        "!unzip -qq train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "18f2c7ba-da0d-472a-a2f2-078f2ff0d105",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18f2c7ba-da0d-472a-a2f2-078f2ff0d105",
        "outputId": "d5e0f8d3-80cb-47f0-c7b7-8ac5e45ae8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.16)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.5.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.41.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.3.1)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.11.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n",
            "Installing collected packages: wrapt, tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.15.0\n",
            "    Uninstalling wrapt-1.15.0:\n",
            "      Successfully uninstalled wrapt-1.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.13.0\n",
            "    Uninstalling tensorflow-estimator-2.13.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.13.1\n",
            "    Uninstalling keras-2.13.1:\n",
            "      Successfully uninstalled keras-2.13.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.13.0\n",
            "    Uninstalling tensorboard-2.13.0:\n",
            "      Successfully uninstalled tensorboard-2.13.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.13.0\n",
            "    Uninstalling tensorflow-2.13.0:\n",
            "      Successfully uninstalled tensorflow-2.13.0\n",
            "Successfully installed keras-2.12.0 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a1fef8a0-b4a5-4a7e-9c8e-0d782f8b00cb",
      "metadata": {
        "id": "a1fef8a0-b4a5-4a7e-9c8e-0d782f8b00cb"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "shutil.rmtree(\"cats_vs_dogs_small\")\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "956b8866-5210-4311-a189-add82c717935",
      "metadata": {
        "id": "956b8866-5210-4311-a189-add82c717935",
        "outputId": "31974392-b277-4214-ed85-f95a6f31f7b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 178, 178, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 89, 89, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 87, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 43, 43, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 9, 9, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 12545     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 991,041\n",
            "Trainable params: 991,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# to build and to run model summary:\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9edbadde-06a1-4b82-9a4a-9c308864149e",
      "metadata": {
        "id": "9edbadde-06a1-4b82-9a4a-9c308864149e"
      },
      "outputs": [],
      "source": [
        "# to Configure the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0345c980-1922-42dd-af5e-d757881ba802",
      "metadata": {
        "id": "0345c980-1922-42dd-af5e-d757881ba802",
        "outputId": "9eb41366-b8c6-42be-d894-beeb8a07fc12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# to declare the image size and batch size to read the images from train. validation and test directories\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6c43d4ac-563b-439a-a00b-25d772c4bd39",
      "metadata": {
        "id": "6c43d4ac-563b-439a-a00b-25d772c4bd39",
        "outputId": "5234aab5-0db8-4d22-da5c-6c3470191b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 18s 92ms/step - loss: 0.7159 - accuracy: 0.5075 - val_loss: 0.6929 - val_accuracy: 0.5600\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 6s 84ms/step - loss: 0.6933 - accuracy: 0.5260 - val_loss: 0.6921 - val_accuracy: 0.5020\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.6970 - accuracy: 0.5470 - val_loss: 0.6839 - val_accuracy: 0.5530\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.6778 - accuracy: 0.5755 - val_loss: 0.7516 - val_accuracy: 0.5360\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 7s 97ms/step - loss: 0.6518 - accuracy: 0.6210 - val_loss: 0.6542 - val_accuracy: 0.6210\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.6032 - accuracy: 0.6875 - val_loss: 0.5859 - val_accuracy: 0.7000\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.5699 - accuracy: 0.7140 - val_loss: 0.5992 - val_accuracy: 0.6800\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 7s 102ms/step - loss: 0.5310 - accuracy: 0.7440 - val_loss: 0.6328 - val_accuracy: 0.6770\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.5001 - accuracy: 0.7565 - val_loss: 0.6004 - val_accuracy: 0.6920\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.4605 - accuracy: 0.7850 - val_loss: 0.5924 - val_accuracy: 0.7040\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 6s 87ms/step - loss: 0.4157 - accuracy: 0.8200 - val_loss: 0.7106 - val_accuracy: 0.7020\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.3541 - accuracy: 0.8525 - val_loss: 0.6774 - val_accuracy: 0.7090\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 5s 68ms/step - loss: 0.3068 - accuracy: 0.8730 - val_loss: 0.7606 - val_accuracy: 0.7080\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 7s 109ms/step - loss: 0.2586 - accuracy: 0.8945 - val_loss: 0.6860 - val_accuracy: 0.7360\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1857 - accuracy: 0.9225 - val_loss: 0.6895 - val_accuracy: 0.7380\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1184 - accuracy: 0.9550 - val_loss: 1.1009 - val_accuracy: 0.7410\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.1182 - accuracy: 0.9565 - val_loss: 1.2758 - val_accuracy: 0.7020\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.0835 - accuracy: 0.9725 - val_loss: 1.2429 - val_accuracy: 0.7310\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0750 - accuracy: 0.9680 - val_loss: 1.3222 - val_accuracy: 0.7310\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0617 - accuracy: 0.9800 - val_loss: 1.5515 - val_accuracy: 0.7340\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0409 - accuracy: 0.9845 - val_loss: 1.8098 - val_accuracy: 0.7240\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0656 - accuracy: 0.9770 - val_loss: 1.4081 - val_accuracy: 0.7450\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0419 - accuracy: 0.9855 - val_loss: 1.5109 - val_accuracy: 0.7360\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 1.9587 - val_accuracy: 0.7320\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 1.5909 - val_accuracy: 0.7570\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0521 - accuracy: 0.9860 - val_loss: 1.8463 - val_accuracy: 0.7430\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 2.0773 - val_accuracy: 0.7230\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 1.9849 - val_accuracy: 0.7200\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.0637 - accuracy: 0.9850 - val_loss: 1.8209 - val_accuracy: 0.7520\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 7s 100ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8528 - val_accuracy: 0.7010\n"
          ]
        }
      ],
      "source": [
        "# to use the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "10e0512a-e031-4d7b-ab78-69356678ad23",
      "metadata": {
        "id": "10e0512a-e031-4d7b-ab78-69356678ad23",
        "outputId": "9c945a00-7278-4149-a81e-62f45eb588e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 34ms/step - loss: 0.5733 - accuracy: 0.6935\n",
            "Test accuracy: 0.693\n"
          ]
        }
      ],
      "source": [
        "# To test the model\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "992e43c2-bb06-44b1-927e-87e785766af2",
      "metadata": {
        "id": "992e43c2-bb06-44b1-927e-87e785766af2"
      },
      "outputs": [],
      "source": [
        "# To declare the Data Augumentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "438bdf0a-bd7f-47f3-963c-b366fe013589",
      "metadata": {
        "id": "438bdf0a-bd7f-47f3-963c-b366fe013589"
      },
      "outputs": [],
      "source": [
        "# Building the model and configuing it\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "3ecc6395-0482-4bd0-9fcc-a04f2ea32d45",
      "metadata": {
        "id": "3ecc6395-0482-4bd0-9fcc-a04f2ea32d45",
        "outputId": "858495f6-119c-48f9-bb30-9616e0744a51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 6s 63ms/step - loss: 0.7112 - accuracy: 0.5145 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.6931 - accuracy: 0.5175 - val_loss: 1.0173 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.6965 - accuracy: 0.5130 - val_loss: 0.6867 - val_accuracy: 0.5660\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.6809 - accuracy: 0.5475 - val_loss: 0.6825 - val_accuracy: 0.5120\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.6474 - accuracy: 0.6170 - val_loss: 0.6643 - val_accuracy: 0.5740\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.6326 - accuracy: 0.6410 - val_loss: 0.6049 - val_accuracy: 0.6700\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.6171 - accuracy: 0.6590 - val_loss: 0.6044 - val_accuracy: 0.6820\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.6152 - accuracy: 0.6560 - val_loss: 0.6066 - val_accuracy: 0.6750\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.5980 - accuracy: 0.6760 - val_loss: 0.6279 - val_accuracy: 0.6220\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.6256 - accuracy: 0.6790 - val_loss: 0.5655 - val_accuracy: 0.6990\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.5737 - accuracy: 0.7110 - val_loss: 0.5580 - val_accuracy: 0.7010\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.5645 - accuracy: 0.7110 - val_loss: 0.6323 - val_accuracy: 0.6680\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.5589 - accuracy: 0.7180 - val_loss: 0.5396 - val_accuracy: 0.7280\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.5415 - accuracy: 0.7275 - val_loss: 0.6275 - val_accuracy: 0.6680\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.5432 - accuracy: 0.7180 - val_loss: 0.5388 - val_accuracy: 0.7470\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.5256 - accuracy: 0.7475 - val_loss: 0.5323 - val_accuracy: 0.7430\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 6s 83ms/step - loss: 0.5156 - accuracy: 0.7510 - val_loss: 0.5635 - val_accuracy: 0.7440\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.5021 - accuracy: 0.7570 - val_loss: 0.5215 - val_accuracy: 0.7510\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.5036 - accuracy: 0.7530 - val_loss: 0.4873 - val_accuracy: 0.7770\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 7s 100ms/step - loss: 0.4942 - accuracy: 0.7725 - val_loss: 0.4911 - val_accuracy: 0.7590\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.4742 - accuracy: 0.7750 - val_loss: 0.5415 - val_accuracy: 0.7530\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.4835 - accuracy: 0.7720 - val_loss: 0.4888 - val_accuracy: 0.7610\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.4647 - accuracy: 0.7880 - val_loss: 0.5505 - val_accuracy: 0.7580\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.4641 - accuracy: 0.7800 - val_loss: 0.5044 - val_accuracy: 0.7630\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.7005 - val_accuracy: 0.7200\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.4286 - accuracy: 0.7980 - val_loss: 0.4668 - val_accuracy: 0.7820\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.4380 - accuracy: 0.7910 - val_loss: 0.4980 - val_accuracy: 0.7740\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 6s 80ms/step - loss: 0.4319 - accuracy: 0.7945 - val_loss: 0.6466 - val_accuracy: 0.7600\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.4114 - accuracy: 0.8120 - val_loss: 0.5652 - val_accuracy: 0.7870\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.4284 - accuracy: 0.8080 - val_loss: 0.4586 - val_accuracy: 0.8110\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 6s 86ms/step - loss: 0.3984 - accuracy: 0.8190 - val_loss: 0.5709 - val_accuracy: 0.7760\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.4074 - accuracy: 0.8155 - val_loss: 0.5760 - val_accuracy: 0.7680\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 7s 108ms/step - loss: 0.4082 - accuracy: 0.8150 - val_loss: 1.0909 - val_accuracy: 0.6650\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.3836 - accuracy: 0.8240 - val_loss: 0.4663 - val_accuracy: 0.8120\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.3769 - accuracy: 0.8345 - val_loss: 0.5726 - val_accuracy: 0.7980\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 7s 102ms/step - loss: 0.3752 - accuracy: 0.8425 - val_loss: 0.4492 - val_accuracy: 0.7900\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.3885 - accuracy: 0.8175 - val_loss: 0.5336 - val_accuracy: 0.7720\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.3476 - accuracy: 0.8465 - val_loss: 0.4385 - val_accuracy: 0.7870\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.3526 - accuracy: 0.8505 - val_loss: 0.4466 - val_accuracy: 0.8110\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 5s 67ms/step - loss: 0.3394 - accuracy: 0.8530 - val_loss: 0.4982 - val_accuracy: 0.7910\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.3403 - accuracy: 0.8590 - val_loss: 0.5594 - val_accuracy: 0.7640\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.3341 - accuracy: 0.8580 - val_loss: 0.6360 - val_accuracy: 0.7490\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.3314 - accuracy: 0.8575 - val_loss: 0.5109 - val_accuracy: 0.8090\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.3213 - accuracy: 0.8645 - val_loss: 0.5632 - val_accuracy: 0.8010\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.3321 - accuracy: 0.8465 - val_loss: 0.4027 - val_accuracy: 0.8270\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.3037 - accuracy: 0.8690 - val_loss: 0.6651 - val_accuracy: 0.7890\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2989 - accuracy: 0.8710 - val_loss: 0.4619 - val_accuracy: 0.8210\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 7s 103ms/step - loss: 0.2864 - accuracy: 0.8765 - val_loss: 0.5238 - val_accuracy: 0.8090\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2880 - accuracy: 0.8745 - val_loss: 0.5114 - val_accuracy: 0.7770\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2846 - accuracy: 0.8830 - val_loss: 0.4942 - val_accuracy: 0.8190\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 6s 87ms/step - loss: 0.2868 - accuracy: 0.8815 - val_loss: 0.4487 - val_accuracy: 0.8280\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2617 - accuracy: 0.8840 - val_loss: 0.4577 - val_accuracy: 0.8240\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.2877 - accuracy: 0.8760 - val_loss: 0.4595 - val_accuracy: 0.8300\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 6s 80ms/step - loss: 0.2308 - accuracy: 0.9105 - val_loss: 0.7043 - val_accuracy: 0.7840\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2688 - accuracy: 0.8865 - val_loss: 0.4569 - val_accuracy: 0.8240\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.2549 - accuracy: 0.8905 - val_loss: 0.4812 - val_accuracy: 0.8190\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.2552 - accuracy: 0.8965 - val_loss: 0.4699 - val_accuracy: 0.8110\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.2567 - accuracy: 0.8970 - val_loss: 0.5138 - val_accuracy: 0.8100\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.2320 - accuracy: 0.9025 - val_loss: 0.6816 - val_accuracy: 0.8140\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.2330 - accuracy: 0.9040 - val_loss: 0.5923 - val_accuracy: 0.7890\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2398 - accuracy: 0.9055 - val_loss: 0.5258 - val_accuracy: 0.8320\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.2322 - accuracy: 0.8995 - val_loss: 0.5255 - val_accuracy: 0.8260\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2333 - accuracy: 0.9070 - val_loss: 0.4674 - val_accuracy: 0.8310\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.2204 - accuracy: 0.9085 - val_loss: 0.5532 - val_accuracy: 0.8230\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.2139 - accuracy: 0.9130 - val_loss: 0.6442 - val_accuracy: 0.8020\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2246 - accuracy: 0.9130 - val_loss: 0.6638 - val_accuracy: 0.7640\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.2267 - accuracy: 0.9170 - val_loss: 0.6723 - val_accuracy: 0.8040\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 6s 81ms/step - loss: 0.2000 - accuracy: 0.9180 - val_loss: 0.5280 - val_accuracy: 0.8380\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2003 - accuracy: 0.9215 - val_loss: 0.5746 - val_accuracy: 0.8190\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2166 - accuracy: 0.9175 - val_loss: 0.8010 - val_accuracy: 0.7970\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.1993 - accuracy: 0.9275 - val_loss: 0.6927 - val_accuracy: 0.8190\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2046 - accuracy: 0.9195 - val_loss: 0.6523 - val_accuracy: 0.8300\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.1851 - accuracy: 0.9270 - val_loss: 0.6810 - val_accuracy: 0.8290\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1924 - accuracy: 0.9295 - val_loss: 1.0020 - val_accuracy: 0.7700\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1967 - accuracy: 0.9255 - val_loss: 0.6408 - val_accuracy: 0.7800\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1919 - accuracy: 0.9275 - val_loss: 0.6942 - val_accuracy: 0.8340\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.1875 - accuracy: 0.9265 - val_loss: 0.6675 - val_accuracy: 0.8260\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1831 - accuracy: 0.9340 - val_loss: 0.7793 - val_accuracy: 0.8090\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2059 - accuracy: 0.9230 - val_loss: 0.6384 - val_accuracy: 0.8270\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.2746 - accuracy: 0.9100 - val_loss: 0.7567 - val_accuracy: 0.8230\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1851 - accuracy: 0.9365 - val_loss: 0.5587 - val_accuracy: 0.8310\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.1949 - accuracy: 0.9300 - val_loss: 0.9141 - val_accuracy: 0.8160\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.1720 - accuracy: 0.9375 - val_loss: 0.6922 - val_accuracy: 0.8530\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 5s 67ms/step - loss: 0.1807 - accuracy: 0.9300 - val_loss: 0.9223 - val_accuracy: 0.8120\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2060 - accuracy: 0.9265 - val_loss: 0.6160 - val_accuracy: 0.8470\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 5s 69ms/step - loss: 0.1896 - accuracy: 0.9345 - val_loss: 0.7178 - val_accuracy: 0.8370\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.1735 - accuracy: 0.9320 - val_loss: 0.6351 - val_accuracy: 0.8550\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1664 - accuracy: 0.9460 - val_loss: 0.7336 - val_accuracy: 0.8300\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1691 - accuracy: 0.9365 - val_loss: 0.7543 - val_accuracy: 0.8460\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.1712 - accuracy: 0.9360 - val_loss: 0.6447 - val_accuracy: 0.8480\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1581 - accuracy: 0.9450 - val_loss: 0.8558 - val_accuracy: 0.8360\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.1536 - accuracy: 0.9420 - val_loss: 0.8207 - val_accuracy: 0.8500\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.1630 - accuracy: 0.9510 - val_loss: 0.8569 - val_accuracy: 0.8440\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.1472 - accuracy: 0.9455 - val_loss: 0.6444 - val_accuracy: 0.8410\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1526 - accuracy: 0.9490 - val_loss: 0.6286 - val_accuracy: 0.8590\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1547 - accuracy: 0.9400 - val_loss: 0.7995 - val_accuracy: 0.8150\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1494 - accuracy: 0.9460 - val_loss: 1.4890 - val_accuracy: 0.7600\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1435 - accuracy: 0.9500 - val_loss: 0.6340 - val_accuracy: 0.8540\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1683 - accuracy: 0.9470 - val_loss: 0.7215 - val_accuracy: 0.8120\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 7s 99ms/step - loss: 0.1737 - accuracy: 0.9385 - val_loss: 0.6598 - val_accuracy: 0.8590\n"
          ]
        }
      ],
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0930390b-a040-457b-ba45-bf32ee8db993",
      "metadata": {
        "id": "0930390b-a040-457b-ba45-bf32ee8db993",
        "outputId": "61862d80-c215-4500-8d34-3d7ba5a050f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 36ms/step - loss: 0.4576 - accuracy: 0.8145\n",
            "Test accuracy: 0.814\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05d158f1-08bc-4ebb-a460-4581e053921e",
      "metadata": {
        "id": "05d158f1-08bc-4ebb-a460-4581e053921e"
      },
      "outputs": [],
      "source": [
        "Question 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "af97de88-4b21-4647-8127-96f19818506d",
      "metadata": {
        "id": "af97de88-4b21-4647-8127-96f19818506d"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "# Increasing the training sample from 1000 to 2000\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "\n",
        "#shutil.rmtree(\"cats_vs_dogs_small_IncreasedTrainSample\")\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_IncreasedTrainSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 2000 samples, test has 1000 samples, and validation has 500 samples\n",
        "make_subset(\"train\", start_index=0, end_index=2500)\n",
        "make_subset(\"validation\", start_index=2500, end_index=3000)\n",
        "make_subset(\"test\", start_index=3000, end_index=4000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "294edacf-59c0-4fde-8d7e-b60ccbbfd873",
      "metadata": {
        "id": "294edacf-59c0-4fde-8d7e-b60ccbbfd873"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ce325f5e-31ce-46d6-a365-fa2495213edd",
      "metadata": {
        "id": "ce325f5e-31ce-46d6-a365-fa2495213edd"
      },
      "outputs": [],
      "source": [
        "# to configure the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "633325ed-583f-440b-967b-a2cfad11b7a0",
      "metadata": {
        "id": "633325ed-583f-440b-967b-a2cfad11b7a0",
        "outputId": "4843de0c-7c2b-4f8a-8203-b285ca7afc15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 7s 82ms/step - loss: 0.6967 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.6976 - accuracy: 0.5660 - val_loss: 0.6724 - val_accuracy: 0.6090\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.6598 - accuracy: 0.6075 - val_loss: 0.7416 - val_accuracy: 0.5380\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.6209 - accuracy: 0.6665 - val_loss: 0.6357 - val_accuracy: 0.6280\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.6213 - accuracy: 0.6760 - val_loss: 0.6113 - val_accuracy: 0.6780\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.5890 - accuracy: 0.6845 - val_loss: 0.5981 - val_accuracy: 0.6700\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 7s 100ms/step - loss: 0.5519 - accuracy: 0.7290 - val_loss: 0.6622 - val_accuracy: 0.6110\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.5158 - accuracy: 0.7440 - val_loss: 0.6018 - val_accuracy: 0.6760\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.4891 - accuracy: 0.7630 - val_loss: 0.5784 - val_accuracy: 0.7020\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.4586 - accuracy: 0.7785 - val_loss: 0.5904 - val_accuracy: 0.7170\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.4215 - accuracy: 0.8085 - val_loss: 0.6578 - val_accuracy: 0.7020\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 6s 87ms/step - loss: 0.3629 - accuracy: 0.8390 - val_loss: 0.6694 - val_accuracy: 0.7230\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.3118 - accuracy: 0.8690 - val_loss: 0.8170 - val_accuracy: 0.7030\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.2720 - accuracy: 0.8865 - val_loss: 0.7525 - val_accuracy: 0.7230\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2321 - accuracy: 0.9055 - val_loss: 0.7731 - val_accuracy: 0.7390\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1818 - accuracy: 0.9295 - val_loss: 0.8875 - val_accuracy: 0.7170\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1493 - accuracy: 0.9420 - val_loss: 1.6710 - val_accuracy: 0.6870\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.1229 - accuracy: 0.9570 - val_loss: 1.2051 - val_accuracy: 0.7160\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.1049 - accuracy: 0.9560 - val_loss: 1.8034 - val_accuracy: 0.6730\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 6s 81ms/step - loss: 0.0853 - accuracy: 0.9705 - val_loss: 1.3959 - val_accuracy: 0.7340\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.0786 - accuracy: 0.9725 - val_loss: 1.4245 - val_accuracy: 0.7190\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0901 - accuracy: 0.9735 - val_loss: 1.3698 - val_accuracy: 0.7260\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 6s 84ms/step - loss: 0.0412 - accuracy: 0.9850 - val_loss: 1.4980 - val_accuracy: 0.7260\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.0684 - accuracy: 0.9755 - val_loss: 1.4437 - val_accuracy: 0.7350\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.0445 - accuracy: 0.9845 - val_loss: 1.9655 - val_accuracy: 0.7290\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 7s 103ms/step - loss: 0.0516 - accuracy: 0.9820 - val_loss: 1.7611 - val_accuracy: 0.7140\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0285 - accuracy: 0.9925 - val_loss: 3.2897 - val_accuracy: 0.6400\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.0790 - accuracy: 0.9840 - val_loss: 1.9099 - val_accuracy: 0.7330\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 2.2228 - val_accuracy: 0.7030\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 2.1584 - val_accuracy: 0.7260\n"
          ]
        }
      ],
      "source": [
        "# to use the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1e6c1e45-5edb-4651-bac1-7c4a35f567ee",
      "metadata": {
        "id": "1e6c1e45-5edb-4651-bac1-7c4a35f567ee",
        "outputId": "2b05ae0b-aef8-4e5a-c253-8e93c0961746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 48ms/step - loss: 0.6326 - accuracy: 0.6860\n",
            "Test accuracy: 0.686\n"
          ]
        }
      ],
      "source": [
        "# to test the model\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52c4f0e-9d09-42c6-aff8-96c282dc3cdf",
      "metadata": {
        "id": "a52c4f0e-9d09-42c6-aff8-96c282dc3cdf"
      },
      "outputs": [],
      "source": [
        "Question 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "279e6dd9-02b7-4030-9519-286ea1eb79b9",
      "metadata": {
        "id": "279e6dd9-02b7-4030-9519-286ea1eb79b9"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "# Increasing the training sample from 2000 to 3500\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_OptimalTrainSamples1\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 1500 samples, test has 1000 samples, and validation has 500 samples\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=3500)\n",
        "make_subset(\"validation\", start_index=3500, end_index=4000)\n",
        "make_subset(\"test\", start_index=4000, end_index=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "56c7c3ab-3b9d-43b6-9196-7b8d260a99a9",
      "metadata": {
        "id": "56c7c3ab-3b9d-43b6-9196-7b8d260a99a9"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "bec223e6-c741-4038-9537-26c2c50fd748",
      "metadata": {
        "id": "bec223e6-c741-4038-9537-26c2c50fd748"
      },
      "outputs": [],
      "source": [
        "#  the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "0dd0d955-2847-4e40-9aa9-0a0983105944",
      "metadata": {
        "id": "0dd0d955-2847-4e40-9aa9-0a0983105944",
        "outputId": "2d1be316-0731-4a44-b146-e196c1058c39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "200/200 [==============================] - 11s 47ms/step - loss: 0.7258 - accuracy: 0.5045 - val_loss: 0.6877 - val_accuracy: 0.6010\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.6801 - accuracy: 0.5842 - val_loss: 0.6283 - val_accuracy: 0.6470\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.6291 - accuracy: 0.6465 - val_loss: 0.5808 - val_accuracy: 0.6720\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.5611 - accuracy: 0.7150 - val_loss: 0.5734 - val_accuracy: 0.7120\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.5321 - accuracy: 0.7377 - val_loss: 0.5195 - val_accuracy: 0.7420\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.4913 - accuracy: 0.7660 - val_loss: 0.5251 - val_accuracy: 0.7520\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 7s 32ms/step - loss: 0.4406 - accuracy: 0.7990 - val_loss: 0.5262 - val_accuracy: 0.7660\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.3790 - accuracy: 0.8313 - val_loss: 0.5557 - val_accuracy: 0.7450\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.3234 - accuracy: 0.8560 - val_loss: 0.4883 - val_accuracy: 0.7860\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.2536 - accuracy: 0.8900 - val_loss: 0.6529 - val_accuracy: 0.7560\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 7s 32ms/step - loss: 0.1976 - accuracy: 0.9205 - val_loss: 0.9127 - val_accuracy: 0.7330\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1553 - accuracy: 0.9390 - val_loss: 0.7785 - val_accuracy: 0.7890\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.1132 - accuracy: 0.9570 - val_loss: 0.9111 - val_accuracy: 0.7810\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1077 - accuracy: 0.9592 - val_loss: 0.9806 - val_accuracy: 0.7810\n",
            "Epoch 15/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0822 - accuracy: 0.9712 - val_loss: 0.9837 - val_accuracy: 0.7990\n",
            "Epoch 16/30\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 0.0937 - accuracy: 0.9697 - val_loss: 0.8827 - val_accuracy: 0.7840\n",
            "Epoch 17/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0684 - accuracy: 0.9747 - val_loss: 1.5636 - val_accuracy: 0.7770\n",
            "Epoch 18/30\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.0794 - accuracy: 0.9762 - val_loss: 1.0130 - val_accuracy: 0.8010\n",
            "Epoch 19/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0646 - accuracy: 0.9808 - val_loss: 1.2886 - val_accuracy: 0.7880\n",
            "Epoch 20/30\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 0.0619 - accuracy: 0.9833 - val_loss: 1.2695 - val_accuracy: 0.8050\n",
            "Epoch 21/30\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.0552 - accuracy: 0.9812 - val_loss: 1.0667 - val_accuracy: 0.7970\n",
            "Epoch 22/30\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.0645 - accuracy: 0.9797 - val_loss: 1.4772 - val_accuracy: 0.7950\n",
            "Epoch 23/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0434 - accuracy: 0.9847 - val_loss: 1.7237 - val_accuracy: 0.7980\n",
            "Epoch 24/30\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0550 - accuracy: 0.9847 - val_loss: 2.1220 - val_accuracy: 0.7800\n",
            "Epoch 25/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0708 - accuracy: 0.9827 - val_loss: 1.7254 - val_accuracy: 0.7860\n",
            "Epoch 26/30\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.0448 - accuracy: 0.9872 - val_loss: 2.4153 - val_accuracy: 0.7770\n",
            "Epoch 27/30\n",
            "200/200 [==============================] - 7s 32ms/step - loss: 0.0613 - accuracy: 0.9868 - val_loss: 1.9393 - val_accuracy: 0.8000\n",
            "Epoch 28/30\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0780 - accuracy: 0.9818 - val_loss: 2.0900 - val_accuracy: 0.7670\n",
            "Epoch 29/30\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.0467 - accuracy: 0.9868 - val_loss: 2.4007 - val_accuracy: 0.7780\n",
            "Epoch 30/30\n",
            "200/200 [==============================] - 9s 41ms/step - loss: 0.0893 - accuracy: 0.9808 - val_loss: 2.2109 - val_accuracy: 0.7970\n"
          ]
        }
      ],
      "source": [
        "# to use the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "5bc303ae-93c0-4fed-8e11-92fa3ae33cf5",
      "metadata": {
        "id": "5bc303ae-93c0-4fed-8e11-92fa3ae33cf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f08b902-5e67-4116-f8ea-343a1467ed24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 51ms/step - loss: 0.2605 - accuracy: 0.9020\n",
            "Test accuracy: 0.902\n"
          ]
        }
      ],
      "source": [
        "# to test the model\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5cAJHLnpCy_m"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "# Increasing the training sample from 3500 to 4500\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_OptimalTrainSamples1\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 1500 samples, test has 1000 samples, and validation has 500 samples\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=4500)\n",
        "make_subset(\"validation\", start_index=4500, end_index=5000)\n",
        "make_subset(\"test\", start_index=5000, end_index=6000)"
      ],
      "id": "5cAJHLnpCy_m"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Q_nQEnWaDD2Q"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "id": "Q_nQEnWaDD2Q"
    },
    {
      "cell_type": "code",
      "source": [
        "#  the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "grI7kFQ8DMch"
      },
      "id": "grI7kFQ8DMch",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to use the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDBUn0WCDOPf",
        "outputId": "7c2a9297-b692-434b-e4d4-8091756af4a7"
      },
      "id": "nDBUn0WCDOPf",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "200/200 [==============================] - 10s 33ms/step - loss: 0.6970 - accuracy: 0.5337 - val_loss: 0.6703 - val_accuracy: 0.6260\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.6638 - accuracy: 0.6112 - val_loss: 0.6123 - val_accuracy: 0.6650\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.6220 - accuracy: 0.6518 - val_loss: 0.5531 - val_accuracy: 0.7090\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 11s 52ms/step - loss: 0.5852 - accuracy: 0.6950 - val_loss: 0.5330 - val_accuracy: 0.7150\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.5283 - accuracy: 0.7430 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.4904 - accuracy: 0.7700 - val_loss: 0.4913 - val_accuracy: 0.7670\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.4427 - accuracy: 0.7893 - val_loss: 0.5060 - val_accuracy: 0.7690\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.3900 - accuracy: 0.8245 - val_loss: 0.5063 - val_accuracy: 0.7850\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.3361 - accuracy: 0.8480 - val_loss: 0.5029 - val_accuracy: 0.8010\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.2815 - accuracy: 0.8808 - val_loss: 0.5272 - val_accuracy: 0.8130\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.2193 - accuracy: 0.9080 - val_loss: 0.7072 - val_accuracy: 0.8000\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 8s 36ms/step - loss: 0.1780 - accuracy: 0.9295 - val_loss: 0.8506 - val_accuracy: 0.7710\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.1327 - accuracy: 0.9463 - val_loss: 0.7388 - val_accuracy: 0.7840\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.1042 - accuracy: 0.9605 - val_loss: 1.1125 - val_accuracy: 0.7710\n",
            "Epoch 15/30\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.0973 - accuracy: 0.9635 - val_loss: 1.1108 - val_accuracy: 0.7690\n",
            "Epoch 16/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0769 - accuracy: 0.9758 - val_loss: 1.0911 - val_accuracy: 0.7890\n",
            "Epoch 17/30\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0927 - accuracy: 0.9690 - val_loss: 1.2259 - val_accuracy: 0.7740\n",
            "Epoch 18/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0752 - accuracy: 0.9730 - val_loss: 1.1808 - val_accuracy: 0.7930\n",
            "Epoch 19/30\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0622 - accuracy: 0.9793 - val_loss: 1.4680 - val_accuracy: 0.7840\n",
            "Epoch 20/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0699 - accuracy: 0.9780 - val_loss: 1.3650 - val_accuracy: 0.7770\n",
            "Epoch 21/30\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.0618 - accuracy: 0.9820 - val_loss: 1.3708 - val_accuracy: 0.7830\n",
            "Epoch 22/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0543 - accuracy: 0.9812 - val_loss: 1.5778 - val_accuracy: 0.7910\n",
            "Epoch 23/30\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0629 - accuracy: 0.9805 - val_loss: 1.8916 - val_accuracy: 0.7730\n",
            "Epoch 24/30\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.0537 - accuracy: 0.9843 - val_loss: 1.8399 - val_accuracy: 0.7870\n",
            "Epoch 25/30\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.0564 - accuracy: 0.9843 - val_loss: 2.0435 - val_accuracy: 0.7840\n",
            "Epoch 26/30\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.0554 - accuracy: 0.9825 - val_loss: 1.8923 - val_accuracy: 0.7790\n",
            "Epoch 27/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0652 - accuracy: 0.9855 - val_loss: 2.1348 - val_accuracy: 0.7750\n",
            "Epoch 28/30\n",
            "200/200 [==============================] - 9s 42ms/step - loss: 0.0594 - accuracy: 0.9822 - val_loss: 1.9992 - val_accuracy: 0.7620\n",
            "Epoch 29/30\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.0626 - accuracy: 0.9843 - val_loss: 2.6742 - val_accuracy: 0.7920\n",
            "Epoch 30/30\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0710 - accuracy: 0.9835 - val_loss: 2.3143 - val_accuracy: 0.7510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to test the model\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpNjAlNGEr62",
        "outputId": "0d9baa78-6c56-4c94-ac3e-08901e0d94e1"
      },
      "id": "QpNjAlNGEr62",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 35ms/step - loss: 0.4287 - accuracy: 0.8015\n",
            "Test accuracy: 0.802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PreTrained Network"
      ],
      "metadata": {
        "id": "UPEIZ0XJFKw3"
      },
      "id": "UPEIZ0XJFKw3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Question 4"
      ],
      "metadata": {
        "id": "uq3GVxIXFnxM"
      },
      "id": "uq3GVxIXFnxM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "\n",
        "shutil.rmtree(\"cats_vs_dogs_small_Pretrained\")\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_Pretrained\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 1500 samples, test has 500 samples, and validation has 500 samples\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ],
      "metadata": {
        "id": "CVLa56aFFvOc"
      },
      "id": "CVLa56aFFvOc",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))\n",
        "conv_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0oJe2PTF1ru",
        "outputId": "7f0df8ea-bb05-4859-fdbc-60b5c005ff64"
      },
      "id": "j0oJe2PTF1ru",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_20 (InputLayer)       [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function to extract features and labels\n",
        "import numpy as np\n",
        "\n",
        "def get_features_and_labels(dataset):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for images, labels in dataset:\n",
        "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
        "        features = conv_base.predict(preprocessed_images)\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "# Extracting the features and labels from datasets\n",
        "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
        "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
        "test_features, test_labels =  get_features_and_labels(test_dataset)\n",
        "train_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbrXblhdGBr8",
        "outputId": "453cf412-4fcf-48bb-e740-8b5167b9bf9e"
      },
      "id": "cbrXblhdGBr8",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 254ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 5, 5, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Running the callback function to monitor validation loss\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSFPjF14Gsu8",
        "outputId": "ee2aa505-cfbf-40ac-99f9-187eb6f4df41"
      },
      "id": "RSFPjF14Gsu8",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 2s 7ms/step - loss: 14.4286 - accuracy: 0.9402 - val_loss: 4.7613 - val_accuracy: 0.9710\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 2.9448 - accuracy: 0.9775 - val_loss: 7.6235 - val_accuracy: 0.9620\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 2.4627 - accuracy: 0.9835 - val_loss: 2.5617 - val_accuracy: 0.9830\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.9300 - accuracy: 0.9920 - val_loss: 3.2113 - val_accuracy: 0.9810\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.9238 - accuracy: 0.9912 - val_loss: 3.8892 - val_accuracy: 0.9760\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3178 - accuracy: 0.9930 - val_loss: 3.5977 - val_accuracy: 0.9760\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6581 - accuracy: 0.9950 - val_loss: 3.1940 - val_accuracy: 0.9790\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.9955 - val_loss: 3.1250 - val_accuracy: 0.9800\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4577 - accuracy: 0.9958 - val_loss: 3.7602 - val_accuracy: 0.9810\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6586 - accuracy: 0.9937 - val_loss: 5.4415 - val_accuracy: 0.9780\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1058 - accuracy: 0.9980 - val_loss: 4.9408 - val_accuracy: 0.9780\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.5081 - accuracy: 0.9952 - val_loss: 4.5141 - val_accuracy: 0.9780\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.9970 - val_loss: 4.1001 - val_accuracy: 0.9810\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2329 - accuracy: 0.9965 - val_loss: 4.6822 - val_accuracy: 0.9760\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9985 - val_loss: 3.8256 - val_accuracy: 0.9800\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9995 - val_loss: 5.0406 - val_accuracy: 0.9780\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1349 - accuracy: 0.9983 - val_loss: 4.2177 - val_accuracy: 0.9780\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0737 - accuracy: 0.9998 - val_loss: 3.7518 - val_accuracy: 0.9800\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1113 - accuracy: 0.9990 - val_loss: 3.6861 - val_accuracy: 0.9830\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9995 - val_loss: 4.1429 - val_accuracy: 0.9810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44aztDLtHE-C",
        "outputId": "aa5329b8-cce3-43fb-defc-1810248b9f1d"
      },
      "id": "44aztDLtHE-C",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.9965\n",
            "Test accuracy: 0.997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to the VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "# Freezing the layers of the pretrained CNN\n",
        "conv_base.trainable = False\n",
        "\n",
        "# UnFreezing the layers of the pretrained CNN\n",
        "conv_base.trainable = True\n",
        "print(\"number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))\n",
        "conv_base.trainable = False\n",
        "print(\"number of trainable weights \"\n",
        "      \"after freezing the conv base:\", len(conv_base.trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEB7osehHPmR",
        "outputId": "581d5b15-521e-481f-ca4c-d3399904b8b4"
      },
      "id": "UEB7osehHPmR",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of trainable weights before freezing the conv base: 26\n",
            "number of trainable weights after freezing the conv base: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Declaring Data Augumentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "# Building the model and configuring it\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "R05Am0_zHdyk"
      },
      "id": "R05Am0_zHdyk",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=60,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdDkX3-aHmWL",
        "outputId": "272e5e6e-c192-4104-c774-21a8a38a3c54"
      },
      "id": "GdDkX3-aHmWL",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "200/200 [==============================] - 11s 46ms/step - loss: 14.5408 - accuracy: 0.9145 - val_loss: 4.6600 - val_accuracy: 0.9770\n",
            "Epoch 2/60\n",
            "200/200 [==============================] - 10s 46ms/step - loss: 7.7759 - accuracy: 0.9467 - val_loss: 3.4007 - val_accuracy: 0.9780\n",
            "Epoch 3/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 5.1162 - accuracy: 0.9530 - val_loss: 2.5294 - val_accuracy: 0.9830\n",
            "Epoch 4/60\n",
            "200/200 [==============================] - 8s 37ms/step - loss: 4.1401 - accuracy: 0.9617 - val_loss: 3.4129 - val_accuracy: 0.9740\n",
            "Epoch 5/60\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 3.8122 - accuracy: 0.9625 - val_loss: 4.7153 - val_accuracy: 0.9630\n",
            "Epoch 6/60\n",
            "200/200 [==============================] - 8s 37ms/step - loss: 2.5942 - accuracy: 0.9645 - val_loss: 3.0211 - val_accuracy: 0.9680\n",
            "Epoch 7/60\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 2.2317 - accuracy: 0.9670 - val_loss: 1.4012 - val_accuracy: 0.9810\n",
            "Epoch 8/60\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 1.7189 - accuracy: 0.9718 - val_loss: 1.4368 - val_accuracy: 0.9790\n",
            "Epoch 9/60\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 1.4063 - accuracy: 0.9707 - val_loss: 0.8483 - val_accuracy: 0.9820\n",
            "Epoch 10/60\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 1.2019 - accuracy: 0.9690 - val_loss: 1.7618 - val_accuracy: 0.9740\n",
            "Epoch 11/60\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.1468 - accuracy: 0.9672 - val_loss: 1.3198 - val_accuracy: 0.9740\n",
            "Epoch 12/60\n",
            "200/200 [==============================] - 11s 52ms/step - loss: 0.8840 - accuracy: 0.9762 - val_loss: 0.6081 - val_accuracy: 0.9840\n",
            "Epoch 13/60\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.8518 - accuracy: 0.9768 - val_loss: 0.7090 - val_accuracy: 0.9860\n",
            "Epoch 14/60\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 0.9691 - accuracy: 0.9718 - val_loss: 0.7539 - val_accuracy: 0.9840\n",
            "Epoch 15/60\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.9013 - accuracy: 0.9747 - val_loss: 1.6498 - val_accuracy: 0.9760\n",
            "Epoch 16/60\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2077 - accuracy: 0.9688 - val_loss: 0.8205 - val_accuracy: 0.9800\n",
            "Epoch 17/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.8185 - accuracy: 0.9718 - val_loss: 0.8660 - val_accuracy: 0.9790\n",
            "Epoch 18/60\n",
            "200/200 [==============================] - 8s 37ms/step - loss: 0.7785 - accuracy: 0.9745 - val_loss: 0.8577 - val_accuracy: 0.9790\n",
            "Epoch 19/60\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.8064 - accuracy: 0.9753 - val_loss: 1.2923 - val_accuracy: 0.9750\n",
            "Epoch 20/60\n",
            "200/200 [==============================] - 9s 44ms/step - loss: 0.8695 - accuracy: 0.9728 - val_loss: 1.4946 - val_accuracy: 0.9700\n",
            "Epoch 21/60\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.7032 - accuracy: 0.9762 - val_loss: 1.4578 - val_accuracy: 0.9740\n",
            "Epoch 22/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.8327 - accuracy: 0.9770 - val_loss: 1.4678 - val_accuracy: 0.9720\n",
            "Epoch 23/60\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.6369 - accuracy: 0.9805 - val_loss: 0.7991 - val_accuracy: 0.9850\n",
            "Epoch 24/60\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.7552 - accuracy: 0.9795 - val_loss: 1.0287 - val_accuracy: 0.9830\n",
            "Epoch 25/60\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.9232 - accuracy: 0.9755 - val_loss: 2.3582 - val_accuracy: 0.9670\n",
            "Epoch 26/60\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 1.0383 - accuracy: 0.9753 - val_loss: 1.0225 - val_accuracy: 0.9780\n",
            "Epoch 27/60\n",
            "200/200 [==============================] - 8s 37ms/step - loss: 0.5720 - accuracy: 0.9847 - val_loss: 2.7602 - val_accuracy: 0.9690\n",
            "Epoch 28/60\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 0.8053 - accuracy: 0.9785 - val_loss: 1.1472 - val_accuracy: 0.9790\n",
            "Epoch 29/60\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.8371 - accuracy: 0.9795 - val_loss: 1.7160 - val_accuracy: 0.9760\n",
            "Epoch 30/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.9458 - accuracy: 0.9775 - val_loss: 1.0538 - val_accuracy: 0.9820\n",
            "Epoch 31/60\n",
            "200/200 [==============================] - 8s 37ms/step - loss: 0.6898 - accuracy: 0.9825 - val_loss: 1.2977 - val_accuracy: 0.9800\n",
            "Epoch 32/60\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 0.8216 - accuracy: 0.9810 - val_loss: 1.4144 - val_accuracy: 0.9780\n",
            "Epoch 33/60\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.7583 - accuracy: 0.9815 - val_loss: 1.4290 - val_accuracy: 0.9790\n",
            "Epoch 34/60\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 0.8788 - accuracy: 0.9778 - val_loss: 1.3690 - val_accuracy: 0.9800\n",
            "Epoch 35/60\n",
            "200/200 [==============================] - 8s 37ms/step - loss: 0.8687 - accuracy: 0.9827 - val_loss: 3.0983 - val_accuracy: 0.9660\n",
            "Epoch 36/60\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 0.7574 - accuracy: 0.9785 - val_loss: 2.3314 - val_accuracy: 0.9710\n",
            "Epoch 37/60\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.7282 - accuracy: 0.9850 - val_loss: 1.2487 - val_accuracy: 0.9810\n",
            "Epoch 38/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.7410 - accuracy: 0.9810 - val_loss: 1.0401 - val_accuracy: 0.9830\n",
            "Epoch 39/60\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.9852 - accuracy: 0.9793 - val_loss: 1.2931 - val_accuracy: 0.9810\n",
            "Epoch 40/60\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.8250 - accuracy: 0.9818 - val_loss: 1.2609 - val_accuracy: 0.9790\n",
            "Epoch 41/60\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.9725 - accuracy: 0.9818 - val_loss: 1.1714 - val_accuracy: 0.9810\n",
            "Epoch 42/60\n",
            "200/200 [==============================] - 8s 37ms/step - loss: 0.9996 - accuracy: 0.9787 - val_loss: 0.9948 - val_accuracy: 0.9820\n",
            "Epoch 43/60\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 0.9435 - accuracy: 0.9800 - val_loss: 1.5254 - val_accuracy: 0.9760\n",
            "Epoch 44/60\n",
            "200/200 [==============================] - 8s 37ms/step - loss: 0.7378 - accuracy: 0.9837 - val_loss: 1.6473 - val_accuracy: 0.9770\n",
            "Epoch 45/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.7581 - accuracy: 0.9852 - val_loss: 1.3663 - val_accuracy: 0.9770\n",
            "Epoch 46/60\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.7110 - accuracy: 0.9852 - val_loss: 1.2969 - val_accuracy: 0.9810\n",
            "Epoch 47/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.9071 - accuracy: 0.9827 - val_loss: 1.7630 - val_accuracy: 0.9750\n",
            "Epoch 48/60\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.7315 - accuracy: 0.9818 - val_loss: 1.2594 - val_accuracy: 0.9860\n",
            "Epoch 49/60\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.6361 - accuracy: 0.9860 - val_loss: 2.8378 - val_accuracy: 0.9680\n",
            "Epoch 50/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.6726 - accuracy: 0.9858 - val_loss: 1.4284 - val_accuracy: 0.9780\n",
            "Epoch 51/60\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.6550 - accuracy: 0.9852 - val_loss: 1.4364 - val_accuracy: 0.9810\n",
            "Epoch 52/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.8365 - accuracy: 0.9845 - val_loss: 1.6401 - val_accuracy: 0.9800\n",
            "Epoch 53/60\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 0.9194 - accuracy: 0.9825 - val_loss: 1.4247 - val_accuracy: 0.9810\n",
            "Epoch 54/60\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.8514 - accuracy: 0.9855 - val_loss: 1.5412 - val_accuracy: 0.9800\n",
            "Epoch 55/60\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.8522 - accuracy: 0.9852 - val_loss: 2.8309 - val_accuracy: 0.9710\n",
            "Epoch 56/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 1.0519 - accuracy: 0.9810 - val_loss: 1.6858 - val_accuracy: 0.9770\n",
            "Epoch 57/60\n",
            "200/200 [==============================] - 8s 37ms/step - loss: 0.6055 - accuracy: 0.9858 - val_loss: 1.8291 - val_accuracy: 0.9770\n",
            "Epoch 58/60\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.7882 - accuracy: 0.9827 - val_loss: 1.8461 - val_accuracy: 0.9780\n",
            "Epoch 59/60\n",
            "200/200 [==============================] - 9s 44ms/step - loss: 0.7823 - accuracy: 0.9827 - val_loss: 1.6329 - val_accuracy: 0.9810\n",
            "Epoch 60/60\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.7261 - accuracy: 0.9845 - val_loss: 1.2422 - val_accuracy: 0.9830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction_with_data_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFr4BFcOKImx",
        "outputId": "73c8fe11-1681-46ef-ea2a-66abab1feba6"
      },
      "id": "FFr4BFcOKImx",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 40ms/step - loss: 0.1532 - accuracy: 0.9945\n",
            "Test accuracy: 0.994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_PretrainedIncreasedSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)"
      ],
      "metadata": {
        "id": "sH5rCallKVsw"
      },
      "id": "sH5rCallKVsw",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))\n",
        "# conv_base.trainable = False"
      ],
      "metadata": {
        "id": "dCBmxcktKbWw"
      },
      "id": "dCBmxcktKbWw",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "make_subset(\"train\", start_index=0, end_index=1500)\n",
        "make_subset(\"validation\", start_index=1500, end_index=2000)\n",
        "make_subset(\"test\", start_index=2000, end_index=3000)\n",
        "\n",
        "# Building the model\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Running the callback function to monitor validation loss\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=30,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk-1kLwEKfcP",
        "outputId": "3ac7f75d-062e-4637-d890-5359a8424062"
      },
      "id": "Fk-1kLwEKfcP",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "125/125 [==============================] - 2s 8ms/step - loss: 9.5280 - accuracy: 0.9410 - val_loss: 3.8333 - val_accuracy: 0.9720\n",
            "Epoch 2/30\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 3.0908 - accuracy: 0.9797 - val_loss: 3.5169 - val_accuracy: 0.9810\n",
            "Epoch 3/30\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2.6990 - accuracy: 0.9830 - val_loss: 4.5592 - val_accuracy: 0.9780\n",
            "Epoch 4/30\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.6183 - accuracy: 0.9872 - val_loss: 3.6109 - val_accuracy: 0.9770\n",
            "Epoch 5/30\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1.0756 - accuracy: 0.9923 - val_loss: 4.0270 - val_accuracy: 0.9750\n",
            "Epoch 6/30\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.9620 - accuracy: 0.9942 - val_loss: 3.9606 - val_accuracy: 0.9830\n",
            "Epoch 7/30\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3828 - accuracy: 0.9958 - val_loss: 5.3838 - val_accuracy: 0.9760\n",
            "Epoch 8/30\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.4578 - accuracy: 0.9955 - val_loss: 4.6922 - val_accuracy: 0.9800\n",
            "Epoch 9/30\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2395 - accuracy: 0.9958 - val_loss: 4.2390 - val_accuracy: 0.9780\n",
            "Epoch 10/30\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1971 - accuracy: 0.9983 - val_loss: 6.4144 - val_accuracy: 0.9760\n",
            "Epoch 11/30\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.9960 - val_loss: 6.4854 - val_accuracy: 0.9780\n",
            "Epoch 12/30\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2435 - accuracy: 0.9975 - val_loss: 3.8356 - val_accuracy: 0.9790\n",
            "Epoch 13/30\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9995 - val_loss: 3.9874 - val_accuracy: 0.9780\n",
            "Epoch 14/30\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1885 - accuracy: 0.9980 - val_loss: 4.1728 - val_accuracy: 0.9810\n",
            "Epoch 15/30\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0585 - accuracy: 0.9985 - val_loss: 4.1495 - val_accuracy: 0.9810\n",
            "Epoch 16/30\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0931 - accuracy: 0.9990 - val_loss: 4.4034 - val_accuracy: 0.9800\n",
            "Epoch 17/30\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9995 - val_loss: 4.1801 - val_accuracy: 0.9780\n",
            "Epoch 18/30\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9990 - val_loss: 4.7379 - val_accuracy: 0.9800\n",
            "Epoch 19/30\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1117 - accuracy: 0.9992 - val_loss: 6.1670 - val_accuracy: 0.9740\n",
            "Epoch 20/30\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9985 - val_loss: 6.2729 - val_accuracy: 0.9780\n",
            "Epoch 21/30\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0800 - accuracy: 0.9995 - val_loss: 5.6749 - val_accuracy: 0.9760\n",
            "Epoch 22/30\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0493 - accuracy: 0.9987 - val_loss: 4.4355 - val_accuracy: 0.9800\n",
            "Epoch 23/30\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0451 - accuracy: 0.9995 - val_loss: 4.9823 - val_accuracy: 0.9800\n",
            "Epoch 24/30\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0404 - accuracy: 0.9990 - val_loss: 4.8645 - val_accuracy: 0.9770\n",
            "Epoch 25/30\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 8.4371e-08 - accuracy: 1.0000 - val_loss: 4.9446 - val_accuracy: 0.9770\n",
            "Epoch 26/30\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3901e-30 - accuracy: 1.0000 - val_loss: 4.9446 - val_accuracy: 0.9770\n",
            "Epoch 27/30\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 2.8331e-35 - accuracy: 1.0000 - val_loss: 4.9446 - val_accuracy: 0.9770\n",
            "Epoch 28/30\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.3987e-23 - accuracy: 1.0000 - val_loss: 4.9446 - val_accuracy: 0.9770\n",
            "Epoch 29/30\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1.7270e-26 - accuracy: 1.0000 - val_loss: 4.9446 - val_accuracy: 0.9770\n",
            "Epoch 30/30\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9987 - val_loss: 7.2104 - val_accuracy: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Qlnq6yLzs1",
        "outputId": "a7e198f4-cfb9-487a-8a0a-9d07f649d401"
      },
      "id": "D5Qlnq6yLzs1",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.9945\n",
            "Test accuracy: 0.994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_PretrainedoptimalSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)"
      ],
      "metadata": {
        "id": "nXWc_-lML2Jy"
      },
      "id": "nXWc_-lML2Jy",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "conv_base.trainable = False\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "QN8gBqTdL8n3"
      },
      "id": "QN8gBqTdL8n3",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "uVmdRuECMIr4"
      },
      "id": "uVmdRuECMIr4",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Train the model with varying training sample sizes\n",
        "sample_sizes = [3000,3500]\n",
        "history_dict = []\n",
        "for size in sample_sizes:\n",
        "    # Set up the training subset\n",
        "    make_subset(\"temp_train\", start_index=0, end_index=size)\n",
        "    make_subset(\"validation\", start_index=size, end_index=size+500)\n",
        "    make_subset(\"test\", start_index=size+500, end_index=size+1500)\n",
        "    train_dataset = image_dataset_from_directory(\n",
        "      new_base_dir / \"temp_train\",\n",
        "      image_size=(180, 180),\n",
        "      batch_size=20)\n",
        "    # Running the callback function to monitor validation loss\n",
        "    callbacks = [\n",
        "      keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")]\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(\n",
        "      train_features, train_labels,\n",
        "      epochs=20,\n",
        "      validation_data=(val_features, val_labels),\n",
        "      callbacks=callbacks)\n",
        "\n",
        "   # Testing the model\n",
        "    test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "    test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "    print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuRU7jxHMMi1",
        "outputId": "94934702-5804-45d1-cd54-3085efbe750c"
      },
      "id": "IuRU7jxHMMi1",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0377 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 3.0007e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.8523e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0123 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0150 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0193 - accuracy: 0.9997 - val_loss: 4.5951e-23 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3964e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9994 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 3.5362e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.000\n",
            "Found 14000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 3.7098e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.6445e-20 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 9.1717e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 9.9577e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.6591e-31 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2971e-23 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.3939e-34 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 3.8750e-25 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 5.6056e-30 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.1752e-28 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 5.5700e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 6.5441e-36 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.4822e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.8617e-27 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3535e-18 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 6.6616e-33 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}